{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1aea258-6299-4dbb-89f7-9c40381f2022",
   "metadata": {},
   "source": [
    "#  Amazon Bedrock Activation Workshop Chapter2: 検索拡張生成(RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d4feae-9487-4148-b9ce-8d0607f8ed50",
   "metadata": {},
   "source": [
    "RAG (Retrieval Augmented Generation, 検索拡張生成)とは、DB・検索インデックス等の信頼できる外部ソースから取得した情報を Prompt に含めることによって、ハルシネーション(幻覚)を抑止するというプロンプトエンジニアリング手法の一種です。  \n",
    "\n",
    "接続する外部ソースに制限はなく、Amazon Kendra のようなエンタープライズサーチシステムや OpenSearch, pinecone といったベクターDB などが一般的に使われます。\n",
    "\n",
    "この Chapter では、RAG の理解を深めていただくことを目的として、埋め込み表現モデルを使った簡易的なベクトル検索システムを作り、LLM と組み合わせることで RAG システムを実装します。  \n",
    "（実際に外部ソースには接続しません）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46fa42e-48fa-421b-83d9-7ec07192a3c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 準備\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5437d6-8936-4983-a73f-76a496b14e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f25b94-2236-4133-a964-af366ba85a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def invoke_claude(text, max_tokens_to_sample=1000): \n",
    "\n",
    "    body = json.dumps({\n",
    "        \"prompt\": f\"\\n\\nHuman:{text}\\n\\nAssistant:\",\n",
    "        \"max_tokens_to_sample\": max_tokens_to_sample,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.9,\n",
    "    })\n",
    "\n",
    "    modelId = 'anthropic.claude-v2'\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    # text\n",
    "    # print(response_body.get('completion'))\n",
    "    return response_body.get('completion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a09ed-00ce-414f-a39b-772cbff2384c",
   "metadata": {},
   "source": [
    "## ベクトル検索システムの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd407e8e-6f39-4b4d-b6db-499573e0b633",
   "metadata": {
    "tags": []
   },
   "source": [
    "今回は、次に挙げるようなAmazon デバイスのリストを検索対象のサンプルとして使います。  \n",
    "実際にはこれらのデータが DB、検索インデックスに格納されていると想定してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d9f3fa-794e-4cef-86a7-d02b010b267b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 検索対象として、Amazonデバイスのリストを使います\n",
    "products = [\n",
    "    {\n",
    "        \"name\": \"Fire TV Stick 第3世代 | HD対応スタンダードモデル |ストリーミングメディアプレイヤー【2020年発売】\",\n",
    "        \"description\": \"\"\"人気のFire TV Stickが第2世代のモデルよりも50%パワフルになりました。フルHDの動画をすばやくストリーミングでき、HDR、Dolby Atmosにも対応しています。(対応するコンテンツや機器が必要です)\n",
    "付属のリモコンではAlexaに話しかけて音声でコンテンツを検索・再生操作できます。お気に入りのコンテンツに簡単にアクセスできるアプリボタンと番組表ボタンが追加されました。対応するテレビ・サウンドバーの電源、ボリュームもコントロールできます。\n",
    "Prime Video、YouTube、Netflix、TVer、U-NEXT、DAZN、Disney+、FOD、Apple TV+などの豊富な映画やビデオを大画面で楽しめる。Silk BrowserによりFacebook、Twitterなど様々なウェブサイトにもアクセス可能。\n",
    "さらにプライム会員なら、Prime Videoの会員特典対象の作品が追加料金なしで見放題。映画、ドラマ、アニメ、お笑い・バラエティ番組など充実のコンテンツ。また、Amazon Music Primeで1億曲がシャッフル再生で聴き放題。\n",
    "Prime Videoチャンネル、ABEMA、Hulu、DAZN、Redbull TVなどのニュース、スポーツ、バラエティ、ドラマ、将棋など様々なジャンルのライブ配信コンテンツが見られます。\n",
    "Amazon Music、Spotifyなどからお好みの曲をストリーミング再生します。*サービスの利用には別途登録・契約や料金が必要な場合があります。\n",
    "簡単セットアップ。お持ちのテレビのHDMI端子に挿してwifiにつなぐだけ。\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Echo (エコー) 第4世代 - スマートスピーカーwith Alexa\",\n",
    "        \"description\": \"\"\"\n",
    "        【一新されたデザインとサウンド】クリアな高音、ダイナミックな中音、そして深みのある低音で、リッチで細やかなサウンドを、設置場所に合わせてパワフルなスピーカーがお届け。\n",
    "【声で音楽をリクエスト】Amazon Music、Apple Music、Spotifyなどからお好みの曲をストリーミング再生。ラジオ局やAudibleのオーディオブックも。\n",
    "【Alexaにおまかせ】ニュースや天気予報を聞いたり、タイマーやアラームを設定したり、対応するスマートデバイスを操作したり、いろいろな質問をしたり。Alexaがさまざまなことをお手伝い。\n",
    "【かんたんスマートホーム】内蔵ハブでZigbee対応スマートデバイスの設定が簡単。\n",
    "【サウンドで満たそう】違う部屋に設置した複数のEchoデバイスで同じ音楽を同時に再生できます。Fire TVと組み合わせて、臨場感のあるエンターテイメントを楽しむことも。\n",
    "【家族や友人とつながる】Echoデバイスを使っている友人とハンズフリーで通話したり、他の部屋に置いたEchoデバイスに呼びかけたり、家中にアナウンスしたりも。\n",
    "【プライバシーに配慮したデザイン】マイクの電源を切ることができるマイク オン/オフ ボタンを用意するなど、何重ものプライバシー保護対策を用いて設計しています。\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Fire HD 8 タブレット - 8インチHD ディスプレイ 32GB ブラック (2022年発売)\",\n",
    "        \"description\": \"\"\"\n",
    "        【前世代機から最大30％高速化】2GB RAM、6コアプロセッサ搭載。\n",
    "【最大13時間稼働バッテリー】同梱の5W USB-C (2.0)充電アダプタで、フル充電まで約5時間。\n",
    "【コンテンツが充実】Prime Video、Netflix、ディズニープラス、U-NEXTなどでお好きな番組や映画をストリーミングやダウンロードで楽しめます。\n",
    "【薄くて、軽くて、丈夫】前世代機より薄く軽く、強化アルミノシリケートグラス製のスクリーン。落下テストでの耐久性はApple iPad Mini (2021)の2倍。\n",
    "【Alexa搭載】Alexaに話しかけて音楽を再生、天気やニュースの確認、Alexa対応スマートホームデバイス（別売り）の操作ができます。\n",
    "【HDビデオ通話】AlexaアプリやZoomアプリをお持ちの友人や家族とビデオ通話が可能。\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Kindle (16GB) 6インチディスプレイ 電子書籍リーダー ブラック\",\n",
    "        \"description\": \"\"\"\n",
    "        より軽く、コンパクトになったKindle。300ppiの高解像度ディスプレイで、文字と画像をくっきり表示。\n",
    "光の反射を抑えた、紙のような読み心地。明るさ調節可能なフロントライトやダークモード搭載で、いつでも快適に読書できます。\n",
    "本に夢中になれる贅沢を。Eメールやソーシャルメディアなどの通知に気を取られることなく、本に集中できる読書のための専用端末。\n",
    "長時間持続するバッテリー。USB-Cケーブルによる1度のフル充電で、最大6週間読書を楽しめます。\n",
    "前モデルの2倍の16GBのストレージ。この1台に数千冊を保存できます（一般的な書籍の場合）。\n",
    "Kindle Unlimitedに会員登録すれば、200万冊以上の本・マンガ・雑誌・洋書が読み放題。新しいお気に入りがきっと見つかります。\n",
    "サステナビリティに配慮。Kindle本体には再生利用素材が使用されています。\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d83a33a-7a0f-4607-946f-eac5ec61c587",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 埋め込み表現モデルの活用\n",
    "まずはAmazon Titan Embeddingモデルを使い、文字列の埋め込み表現を取得する関数を定義します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d0d3e-53e1-478f-b195-b23d4b3e4a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 入力文字列の埋め込み表現を取得する関数\n",
    "def get_embedding(text: str) -> np.ndarray:\n",
    "    body = json.dumps({\n",
    "    \"inputText\": text\n",
    "    })\n",
    "\n",
    "    modelId =  \"amazon.titan-embed-text-v1\"\n",
    "    accept = '*/*'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    # print(response)\n",
    "    response_embeddings = np.array(response_body.get('embedding'))\n",
    "    \n",
    "    return response_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a84cb-88e8-4077-b411-fa8436707dbf",
   "metadata": {},
   "source": [
    "2つの文字列間の類似度を計算するため、埋め込み表現のベクトルどうしで、コサイン類似度を計算するような関数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5dd6b-e75a-4fca-9ccf-680245fa8598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2つのベクトルのコサイン類似度を計算する関数\n",
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f4208-2755-4928-845e-d1dbc8f71ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(cos_sim(get_embedding('富士山は日本で一番高い山です'), get_embedding('日本最高峰はなんですか')))\n",
    "print(cos_sim(get_embedding('富士山は日本で一番高い山です'), get_embedding('バナナはおやつに入りますか')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53da7e-fa2d-44af-909c-d028fa2a6666",
   "metadata": {},
   "source": [
    "実行結果から、関連性の高い文章の類似度が高くなることが確認できます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc53ea-c47c-4dce-a7d1-dec159185988",
   "metadata": {},
   "source": [
    "### 商品リストの埋め込み表現の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc15a230-7e7e-47d4-bded-f05444b242d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "products_embeddings = []\n",
    "for ind, product in enumerate(products):\n",
    "    embeddings = get_embedding(product['name'])\n",
    "    products[ind]['embedding'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e36e3f-f7f3-41c8-bff4-4504994823b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cb9a7-012c-4767-b6d7-8cf27b9e18ae",
   "metadata": {},
   "source": [
    "### 商品リストを検索する関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a272e-3aa0-475f-b7fa-72f45b718664",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "# クエリの埋め込み表現を受け取り、商品リストの埋め込み表現の中から最も類似度が高いエントリを検索する関数\n",
    "def search_embeddings(query_embedding: np.ndarray, arr: List, embd_name = 'embedding', threshold = 0.5) -> List:\n",
    "    cos_sims = []\n",
    "    \n",
    "    # リストの中の埋め込み表現とのコサイン類似度を計算\n",
    "    for embd in [e[embd_name] for e in arr]:\n",
    "        cos_sims.append(cos_sim(embd, query_embedding))\n",
    "    \n",
    "    # 類似度の降順にソート\n",
    "    decorated = [(cos_sims[i], i, element) for i, element in enumerate(arr)]\n",
    "    decorated.sort(reverse=True)\n",
    "    \n",
    "    # 類似度が一定のしきい値を超えているエントリのみを返す\n",
    "    result = [(cos_sim, element) for cos_sim, _, element in decorated if cos_sim > threshold]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f71cb-e935-49ab-821a-9789b7c36ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"電子書籍\"\n",
    "result = search_embeddings(get_embedding(query), products)\n",
    "print('コサイン類似度: ', result[0][0])\n",
    "print('名前: ', result[0][1]['name'])\n",
    "print('説明: ', result[0][1]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b448a7-cf0a-42a3-a468-724005504dba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"動画配信\"\n",
    "result = search_embeddings(get_embedding(query), products)\n",
    "print('コサイン類似度: ', result[0][0])\n",
    "print('名前: ', result[0][1]['name'])\n",
    "print('説明: ', result[0][1]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baa6f58-6544-439f-8757-287a296732ed",
   "metadata": {},
   "source": [
    "## RAG の作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed8c3b-3a52-46ba-895a-b9e16800a680",
   "metadata": {},
   "source": [
    "ベクトル検索エンジンと LLM を組み合わせて、検索結果をもとに質問に答えるような RAG システムを構築します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c0533-ef85-4fd7-9fb5-3847bae07ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLMのタスク指示をinstructionで、ユーザからのクエリをquestionに、検索結果をcontextへ反映します。\n",
    "prompt_template = \\\n",
    "\"\"\"\n",
    "<instruction>\n",
    "あなたは親切なAIボットです。ユーザからの質問に対してcontextで与えられている情報をもとに誠実に回答します。\n",
    "ただし、質問に対する答えがcontextに書かれていない場合は、正直に「分かりません。」と回答してください。\n",
    "</instruction>\n",
    "<question>\n",
    "{query}\n",
    "</question>\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917fc1b-35a9-4cbd-a694-6f3921886959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"電子書籍に適した端末\"\n",
    "# query内容をもとにproductsを検索\n",
    "search_result = search_embeddings(get_embedding(query), products)\n",
    "context = ''\n",
    "if len(search_result) > 0:\n",
    "    context = 'name: '+search_result[0][1]['name'] + 'description:' + search_result[0][1]['description']\n",
    "\n",
    "result = invoke_claude(prompt_template.format(query=query, context=context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a99501c-a872-4011-a2a2-328461f5a2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('検索結果:\\n', context)\n",
    "print('LLMによる回答:\\n', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b779848-37dc-4556-b1ad-b534920f9232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"動画配信を楽しむには何を買えばいいですか\"\n",
    "# query内容をもとにproductsを検索\n",
    "search_result = search_embeddings(get_embedding(query), products)\n",
    "context = ''\n",
    "if len(search_result) > 0:\n",
    "    context = 'name: '+search_result[0][1]['name'] + 'description:' + search_result[0][1]['description']\n",
    "\n",
    "result = invoke_claude(prompt_template.format(query=query, context=context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdf5043-0b7e-4c38-8b3c-07e99cfc135b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('検索結果:\\n', context)\n",
    "print('LLMによる回答:\\n', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f98f4ca-71c0-41ee-b1c3-62581a3e45ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"私の父は読書が好きです。どういったプレゼントを贈るのが良いでしょうか\"\n",
    "# query内容をもとにproductsを検索\n",
    "search_result = search_embeddings(get_embedding(query), products)\n",
    "context = ''\n",
    "if len(search_result) > 0:\n",
    "    context = 'name: '+search_result[0][1]['name'] + 'description:' + search_result[0][1]['description']\n",
    "\n",
    "\n",
    "result = invoke_claude(prompt_template.format(query=query, context=context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd04586b-0db9-45d7-86d8-7e897cc852f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('検索結果:\\n', context)\n",
    "print('LLMによる回答:\\n', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffefb7f0-dfc9-4f1a-b2ff-b8c5e6c6a399",
   "metadata": {},
   "source": [
    "以上のように、検索システムと LLM を組み合わせることで、情報源をもとにした信頼できる回答を生成することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6dc92c-9059-420c-9009-1fc1fef9e192",
   "metadata": {},
   "source": [
    "## RAG の性能評価"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ed86d-a753-4353-ab82-1f2aff606e6d",
   "metadata": {},
   "source": [
    "RAG による効果も測定する必要があります。  \n",
    "RAG の評価方法として、様々な方式[1](https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG), [2](https://betterprogramming.pub/llamaindex-how-to-evaluate-your-rag-retrieval-augmented-generation-applications-2c83490f489)が提案されています。  \n",
    "今回は、LLM による回答結果を 1:良かった、0:悪かった の2値で人によってフィードバックし、スコアリングします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4523fad-f6cd-4cf5-b156-46c79bcfb101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_query = [\n",
    "    \"電子書籍に適した端末\",\n",
    "    \"動画配信を楽しむには何を買えばいいですか\",\n",
    "    \"安価なタブレット端末が欲しいです。\",\n",
    "    \"私の祖母は植物の動画が大好きで、いつもスマホでYouTubeを見ています。そんな彼女に贈り物を贈りたいのですが、何を贈ると喜んでもらえるでしょうか\",\n",
    "    \"私には5歳になる娘がいます。彼女はPrime Videoが大好きで、いつもiPadで動画を見ています。そんな彼女に贈り物を贈りたいのですが、何がいいでしょうか\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51089c2-f616-4a16-97e7-f32a751996ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag_search(query: str) -> str:\n",
    "    prompt_template = \\\n",
    "    \"\"\"\n",
    "    <instruction>\n",
    "    あなたは親切なAIボットです。ユーザからの質問に対してcontextで与えられている情報をもとに誠実に回答します。\n",
    "    ただし、質問に対する答えがcontextに書かれていない場合は、正直に「分かりません。」と回答してください。\n",
    "    </instruction>\n",
    "    <question>\n",
    "    {query}\n",
    "    </question>\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    \"\"\"\n",
    "    \n",
    "    search_result = search_embeddings(get_embedding(query), products)\n",
    "    context = ''\n",
    "    if len(search_result) > 0:\n",
    "        context = 'name: '+search_result[0][1]['name'] + 'description:' + search_result[0][1]['description']\n",
    "\n",
    "\n",
    "    result = invoke_claude(prompt_template.format(query=query, context=context))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5760b34-8cf6-49fc-b1f5-c3818866ec9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_feedback = []\n",
    "\n",
    "for query in test_query:\n",
    "    result = rag_search(query)\n",
    "    print('query:\\n', query)\n",
    "    print('result:\\n', result)\n",
    "    print('\\n以上の回答を 1:良かった、0:悪かった の いずれかでフィードバックしてください。:', end='')\n",
    "    feedback = int(input())\n",
    "    user_feedback.append(feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e28363-f462-49ec-a50d-1eb79587b56b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csat = sum(user_feedback) / len(user_feedback)\n",
    "print('顧客満足度: ', csat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e677410-d575-4877-8150-8433a8deb45a",
   "metadata": {
    "tags": []
   },
   "source": [
    "このように、生成結果をフィードバックする仕組みがあると、RAGによる効果を測定することができます。  \n",
    "得られたフィードバックをもとに、よりよい回答が出せるようなプロンプトや検索の仕組みを考えてみましょう"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6e58c1-683d-4710-83b5-bd9f947b4b7b",
   "metadata": {},
   "source": [
    "## RAG の改善"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfbe177-f392-4b4c-9771-f8aae361ad65",
   "metadata": {
    "tags": []
   },
   "source": [
    "上記の RAG による回答を見ると、単純な質問であれば答えられるものの、シチュエーションを踏まえた複雑な質問になると検索精度が下がり回答が生成できていないことがわかります。  \n",
    "そこで、クエリをいきなりベクトル検索するのではなく、まずは LLM でキーワードを抽出してから検索するような仕組みに変えてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0e2df-ca0e-4e26-b104-acdad6997cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \\\n",
    "\"\"\"\n",
    "<instruction> \n",
    "あなたは親切なAIボットです。ユーザからの質問に対して正直に答えるために検索を行うことができます。\n",
    "質問の内容をもとに、最適な検索クエリを出力してください。\n",
    "ただし、返答作成時はexampleに書かれているような単語のリストで回答してください。\n",
    "また、単語リスト以外の情報やコメントは含めないでください。\n",
    "</instruction>\n",
    "<question>{question}</question>\n",
    "<example>\n",
    "週末 旅行先 人気\n",
    "</example>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b48df-c5cc-41f6-91ef-67c3680521f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(question = test_query[4])\n",
    "result = invoke_claude(prompt)\n",
    "print('prompt:', prompt)\n",
    "print('output:', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb77a6-57a9-4553-8079-83cce3402fb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "キーワードが抽出できていることがわかります。ではベクトル検索と組み合わせてみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a845d-08d0-4d2e-b459-28466f17da11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag_search2(query: str) -> str:\n",
    "    search_prompt_template = \\\n",
    "    \"\"\"\n",
    "    <instruction> \n",
    "    あなたは親切なAIボットです。ユーザからの質問に対して正直に答えるために検索を行うことができます。\n",
    "    質問の内容をもとに、最適な検索クエリを出力してください。\n",
    "    ただし、返答作成時はexampleに書かれているような単語のリストで回答してください。\n",
    "    また、単語リスト以外の情報やコメントは含めないでください。\n",
    "    </instruction>\n",
    "    <question>{question}</question>\n",
    "    <example>\n",
    "    週末 旅行先 人気\n",
    "    </example>\n",
    "    \"\"\"\n",
    "    search_prompt = search_prompt_template.format(question=query)\n",
    "    search_query = invoke_claude(search_prompt)\n",
    "    \n",
    "    print(\"keyword: \", search_query)\n",
    "    \n",
    "    \n",
    "    search_result = search_embeddings(get_embedding(search_query), products)\n",
    "    context = ''\n",
    "    if len(search_result) > 0:\n",
    "        context = 'name: '+search_result[0][1]['name'] + 'description:' + search_result[0][1]['description']\n",
    "\n",
    "        \n",
    "    prompt_template = \\\n",
    "    \"\"\"\n",
    "    <instruction>\n",
    "    あなたは親切なAIボットです。ユーザからの質問に対してcontextで与えられている情報をもとに誠実に回答します。\n",
    "    ただし、質問に対する答えがcontextに書かれていない場合は、正直に「分かりません。」と回答してください。\n",
    "    </instruction>\n",
    "    <question>\n",
    "    {query}\n",
    "    </question>\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    \"\"\"\n",
    "    result = invoke_claude(prompt_template.format(query=query, context=context))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1306c-cb25-41d5-b698-e7f399e10dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for query in test_query:\n",
    "    print('query:', query)\n",
    "    print('前者のRAG')\n",
    "    print(rag_search(query))\n",
    "    print('後者のRAG')\n",
    "    print(rag_search2(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b4dc7d-624d-4a41-a93c-d56da1842b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(rag_search2(test_query[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1ca7d-4741-4e24-951d-25aa87c82866",
   "metadata": {
    "tags": []
   },
   "source": [
    "いかがでしょうか、結果は改善されたでしょうか  \n",
    "適宜プロンプトも変えて様々なセットを試して見てください。 　\n",
    "\n",
    "RAG システムの改善には複数の要素が作用するため、適切な改善を行うためには、統一的な指標を定めておくことが重要です。\n",
    "あらかじめ想定質問のセットを作っておくことは、RAG による効果を測定する上で効果的です。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b59a156-6826-487f-8793-3485d94d96b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fecf914-610d-42fd-87e2-2b3cd46aab8a",
   "metadata": {},
   "source": [
    "このチャプターではRAGの概要と基本的な考え方をご紹介しました。  \n",
    "今回はベクトルサーチベースで実装しましたが、精度向上のためには、外部DBの選定も重要になります。  \n",
    "ぜひ自分たちに最適な構成を一緒に見つけていきましょう。"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
